{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instsall tar2tf module\n",
    "! pip3 install ../ais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list available ais buckets\n",
    "!ais create bucket imagenet-tar\n",
    "!ais ls ais://"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaruNGayy\r\n",
      "Run `ais show download aaruNGayy` to monitor the progress of downloading.\r\n"
     ]
    }
   ],
   "source": [
    "!ais start download \"gs://lpr-gtc2020/oisubset-train-{0000..0003}.tar\" ais://imagenet-tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list contents of your bucket\n",
    "# wait until download is finished.\n",
    "!ais ls ais://imagenet-tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import randrange\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from ais_tar2tf import Dataset\n",
    "from ais_tar2tf.ops import Select, Decode, Convert, Resize, Rotate, Func, Rename\n",
    "\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "# ADJUST Dataset PARAMETERS BELOW\n",
    "\n",
    "BUCKET_NAME = \"imagenet-tar\"\n",
    "PROXY_URL = \"http://172.17.0.2:8080\"\n",
    "\n",
    "INPUT_SHAPE = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_parser(record):\n",
    "    keys_to_features = {\n",
    "        \"json\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"img\": tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    parsed = tf.io.parse_single_example(record, keys_to_features)\n",
    "    # TODO: adjust label value based on \"json\" field.\n",
    "    return tf.image.decode_jpeg(parsed[\"img\"]), tf.cast(randrange(10), tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create Dataset.\n",
    "# tar records will be transformed according to:\n",
    "# Rename(img=\"png;jpg;jpeg\"), Decode(\"img\"), Rotate(\"img\"), Resize(\"img\", (224, 224)) operations,\n",
    "# meaning that png, jpg and jpeg will be renamed to img, then bytes under \"img\" in tar-record will be decoded as an image,\n",
    "# Rotated by random angle and then Resized to (224, 224).\n",
    "# Datapoints will be constructed from \"img\" and \"json\" tar records entries\n",
    "conversions = [Rename(img=\"png;jpg;jpeg\"), Decode(\"img\"), Rotate(\"img\"), Resize(\"img\", (224, 224))]\n",
    "selections = [\"img\", \"json\"]\n",
    "\n",
    "# Initialization of an Dataset.\n",
    "# It may take a moment as it starts ETL containers in the cluster.\n",
    "# After finished working with Dataset, call dataset.stop()\n",
    "dataset = Dataset(BUCKET_NAME, PROXY_URL, conversions, selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remote conversions and selections execution is enabled by default.\n",
    "# Datasets will be prepared from \"oisubset-train-{0000..0003}.tar\" files.\n",
    "# Prefetches dataset, repeats it 100 times and splits into batches of size BATCH_SIZE\n",
    "train_dataset = dataset.load(\"oisubset-train-{0000..00001}.tar\", record_to_example=record_parser\n",
    ").cache().repeat(100).batch(BATCH_SIZE)\n",
    "\n",
    "test_dataset = dataset.load(\"oisubset-train-{0002..0003}.tar\", record_to_example=record_parser\n",
    ").cache().repeat(100).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING PART BELOW\n",
    "inputs = keras.Input(shape=(\n",
    "    224,\n",
    "    224,\n",
    "    3,\n",
    "), name=\"images\")\n",
    "x = layers.Flatten()(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(x)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-4), loss=keras.losses.mean_squared_error, metrics=[\"acc\"])\n",
    "model.summary()\n",
    "\n",
    "model.fit(train_dataset, epochs=EPOCHS, steps_per_epoch=BATCH_SIZE)\n",
    "result = model.evaluate(test_dataset)\n",
    "print(dict(zip(model.metrics_names, result)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop created in the cluster ETL.\n",
    "dataset.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
